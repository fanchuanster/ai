1. mlflow run . -P max_iter=200 --env-manager=local

2. mlflow models serve -m runs:/9ff0e76833f9496e887235e54c38a50c/iris_model -p 1234 --env-manager local

3. curl -X POST http://127.0.0.1:1234/invocations -H "Content-Type: application/json" -d "{\"instances\": [[5.1, 3.5, 1.4, 0.2]]}"

4. mlflow ui --backend-store-uri file:///C:/Users/donwen/Desktop/tm/ai/mlflow/mlruns --default-artifact-root file:///C:/Users/donwen/Desktop/tm/ai/mlflow/artifacts

5. mlflow server \
  --backend-store-uri sqlite:///C:/Users/donwen/Desktop/tm/ai/mlflow/mlflow.db \
  --default-artifact-root file:///C:/Users/donwen/Desktop/tm/ai/mlflow/artifacts \
  --host 127.0.0.1 \
  --port 5000

6. two options:
1) with no mlflow settings in code, configured in mlflow run arguments
mlflow run . \
  -P max_iter=200 \
  --tracking-uri http://127.0.0.1:5000 \
  --experiment-name IrisClassifierExperiment \
  --env-manager=local
2)
mlflow.set_tracking_uri("http://127.0.0.1:5000")
mlflow.set_experiment("IrisClassifierExperiment")
with mlflow.start_run():
    mlflow.log_param(...)
    mlflow.log_metric(...)
and run with: python train.py 200
